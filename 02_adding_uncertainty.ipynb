{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic II: adding uncertainty"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the previous tutorial, Basic I: first steps, we created a\n",
    "deterministic  hydro-thermal scheduling model. In this tutorial, we extend the\n",
    "problem by adding uncertainty."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notably missing from our previous model were inflows. Inflows are the water\n",
    "that flows into the reservoir through rainfall or rivers. These inflows are\n",
    "uncertain, and are the cause of the main trade-off in hydro-thermal\n",
    "scheduling: the desire to use water now to generate cheap electricity, against\n",
    "the risk that future inflows will be low, leading to blackouts or expensive\n",
    "thermal generation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For our simple model, we assume that the inflows can be modelled by a discrete\n",
    "distribution with the three outcomes given in the following table:\n",
    "\n",
    "| ω    |   0 |  50 | 100 |\n",
    "| ---- | --- | --- | --- |\n",
    "| P(ω) | 1/3 | 1/3 | 1/3 |"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The value of the noise (the random variable) is observed by the agent at the\n",
    "start of each stage. This makes the problem a _wait-and-see_ or\n",
    "_hazard-decision_ formulation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To represent this, we can draw the following picture. The wavy lines denote\n",
    "the uncertainty arriving into the start of each stage (node).\n",
    "\n",
    "![Linear policy graph](assets/stochastic_linear_policy_graph.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to adding this uncertainty to the model, we also need to modify\n",
    "the dynamics to include `inflow`:\n",
    "\n",
    "`volume.out = volume.in + inflow - hydro_generation - hydro_spill`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To add an uncertain variable to the model, we create a new JuMP variable\n",
    "`inflow`, and then call the function `SDDP.parameterize`. The\n",
    "`SDDP.parameterize` function takes three arguments: the subproblem, a\n",
    "vector of realizations, and a corresponding vector of probabilities."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SDDP, GLPK\n",
    "\n",
    "model = SDDP.LinearPolicyGraph(\n",
    "    stages = 3,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = GLPK.Optimizer\n",
    ") do subproblem, t\n",
    "    # Define the state variable.\n",
    "    @variable(subproblem, 0 <= volume <= 200, SDDP.State, initial_value = 200)\n",
    "    # Define the control variables.\n",
    "    @variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation   >= 0\n",
    "        hydro_spill        >= 0\n",
    "        inflow\n",
    "    end)\n",
    "    # Define the constraints\n",
    "    @constraints(subproblem, begin\n",
    "        volume.out == volume.in + inflow - hydro_generation - hydro_spill\n",
    "        demand_constraint, thermal_generation + hydro_generation == 150.0\n",
    "    end)\n",
    "    # Define the objective for each stage `t`. Note that we can use `t` as an\n",
    "    # index for t = 1, 2, 3.\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    @stageobjective(subproblem, fuel_cost[t] * thermal_generation)\n",
    "    # Parameterize the subproblem.\n",
    "    SDDP.parameterize(subproblem, [0.0, 50.0, 100.0], [1/3, 1/3, 1/3]) do ω\n",
    "        JuMP.fix(inflow, ω)\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note how we use the JuMP function\n",
    "[`JuMP.fix`](http://www.juliaopt.org/JuMP.jl/v0.19/variables/#JuMP.fix) to set\n",
    "the value of the `inflow` variable to `ω`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and simulating the policy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As in Basic I: first steps, we train the policy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "SDDP.train(model; iteration_limit = 10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also simulate the policy. Note that this time, the simulation is\n",
    "stochastic. One common approach to quantify the quality of the policy is to\n",
    "perform  a Monte Carlo simulation and then form a confidence interval for the\n",
    "expected cost. This confidence interval is an estimate for the upper bound."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to the confidence interval, we can calculate the lower bound using\n",
    "`SDDP.calculate_bound`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Statistics\n",
    "\n",
    "simulations = SDDP.simulate(model, 500)\n",
    "\n",
    "objective_values = [\n",
    "    sum(stage[:stage_objective] for stage in sim) for sim in simulations\n",
    "]\n",
    "\n",
    "μ = round(mean(objective_values), digits = 2)\n",
    "\n",
    "ci = round(1.96 * std(objective_values) / sqrt(500), digits = 2)\n",
    "\n",
    "println(\"Confidence interval: \", μ, \" ± \", ci)\n",
    "println(\"Lower bound: \", round(SDDP.calculate_bound(model), digits = 2))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to simulating the primal values of variables, we can also pass\n",
    "`SDDP.jl` custom recorder functions. Each of these functions takes one\n",
    "argument, the JuMP subproblem, and returns anything you can compute. For\n",
    "example, the dual of the demand constraint (which we named\n",
    "`demand_constraint`) corresponds to the price we should charge for\n",
    "electricity, since it represents the cost of each additional unit of demand.\n",
    "To calculate this, we can go"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "simulations = SDDP.simulate(\n",
    "    model,\n",
    "    1,\n",
    "    custom_recorders = Dict{Symbol, Function}(\n",
    "        :price => (sp) -> JuMP.dual(sp[:demand_constraint])\n",
    "    )\n",
    ")\n",
    "\n",
    "prices = [stage[:price] for stage in simulations[1]]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This concludes our second tutorial for `SDDP.jl`. In the next tutorial, [Basic\n",
    "III: objective uncertainty](@ref), we extend the uncertainty to the fuel cost."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "kernelspec": {
   "name": "julia-1.5",
   "display_name": "Julia 1.5.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
